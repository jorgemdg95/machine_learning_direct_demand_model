{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b23670ba",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbfc544d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "from multiprocessing import Process, Manager, Semaphore\n",
    "from joblib import Parallel, delayed\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import seaborn as sns\n",
    "import os\n",
    "from tkinter import ttk, simpledialog, messagebox, font"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884653d5",
   "metadata": {},
   "source": [
    "# Reading database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8d3682f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get current working directory\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "# Name training database\n",
    "file_path = os.path.join(current_directory, 'training_dataset.csv')\n",
    "\n",
    "# Read training database\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Remove multicollinearity variables\n",
    "df = df.drop(['vrm','ms_single','ms_married','ms_widowed','edu_graduate','modet_taxi','veh_three','veh_fourplus',\n",
    "              'sex_male','age_64plus','income_200','income_200plus','race_indian',\n",
    "              'race_other','race_hawaiian','race_mixed','race_white','modet_drive',\n",
    "              'ms_divorced','ms_separated'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a111a0a",
   "metadata": {},
   "source": [
    "## Standardize the training and prediction datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7dd606f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract categorical variables\n",
    "cluster_column = df['Cluster']\n",
    "upt_column = df['upt']\n",
    "month_column = df['month']\n",
    "df = df.drop(['Cluster','upt','month'], axis=1)\n",
    "\n",
    "# Fit the scaler on the training data\n",
    "scaler = StandardScaler(with_mean = True, # center the data on mean = zero\n",
    "                        with_std=True) # set standard deviation = 1\n",
    "scaler.fit(df)\n",
    "\n",
    "# Transform the training dataset\n",
    "scaled_data = scaler.transform(df)\n",
    "\n",
    "# Construct the database using the standarize data\n",
    "df_names = df.columns.tolist()\n",
    "df = pd.DataFrame(scaled_data, columns = df_names)\n",
    "df['Cluster'] = cluster_column\n",
    "df['upt'] = upt_column\n",
    "df['month'] = month_column\n",
    "\n",
    "# Transform variables to categorical variables\n",
    "df['month'] = df['month'].astype('category')\n",
    "df['Cluster'] = df['Cluster'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f055373-1482-4425-b564-2afd4419407f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read observations to predict\n",
    "file_path = os.path.join(current_directory, 'prediction_dataset.csv')\n",
    "x_prediction = pd.read_csv(file_path)\n",
    "\n",
    "# Remove multicollinearity variables\n",
    "x_prediction = x_prediction.drop(['vrm','ms_single','ms_married','ms_widowed','edu_graduate','modet_taxi','veh_three','veh_fourplus',\n",
    "                                  'sex_male','age_64plus','income_200','income_200plus','race_indian',\n",
    "                                  'race_other','race_hawaiian','race_mixed','race_white','modet_drive',\n",
    "                                  'ms_divorced','ms_separated'], axis=1)\n",
    "\n",
    "# Remove categorical variables\n",
    "month_column_test = x_prediction['month']\n",
    "x_prediction = x_prediction.drop(['month'], axis=1)\n",
    "\n",
    "# Transform the testing data using the fitted scaler\n",
    "x_prediction = scaler.transform(x_prediction)\n",
    "\n",
    "# Construct the standardized testing dataset\n",
    "x_prediction = pd.DataFrame(x_prediction, columns=df_names)\n",
    "x_prediction['month'] = month_column_test\n",
    "\n",
    "# Transform variables to categorical variables\n",
    "x_prediction['month'] = x_prediction['month'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b677ea43-45f1-4d16-ba46-5bb41157d26d",
   "metadata": {},
   "source": [
    "# Request the cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3cd42b5-2d7a-4ed1-acbc-6dfb73b69317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Request the number of cluster to be analyzed\n",
    "while True:\n",
    "    cluster_number = simpledialog.askstring(\"Input\", \"Please enter the Cluster ID, including 1, 2, 3, 4, or 5:\")\n",
    "    if cluster_number and cluster_number.isdigit() and int(cluster_number) in {1, 2, 3, 4, 5}:\n",
    "        cluster_number = int(cluster_number)\n",
    "        break\n",
    "    else:\n",
    "        messagebox.showerror(\"Error\", \"Invalid Cluster ID. Please enter a valid number (1, 2, 3, 4, or 5).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db82d018-cb7c-4e1c-957f-2b509e832fed",
   "metadata": {},
   "source": [
    "# Run the models with default and optimal value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4ff4a49-56c4-4d74-b6c2-ee40a0c0265b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset training dataset keeping only the correct cluster\n",
    "current_df = df[df['Cluster'] == cluster_number - 1 ]\n",
    "\n",
    "# Define the features (X) and target (y)\n",
    "X = current_df.drop(columns=['upt']) \n",
    "X = X.drop(columns=['Cluster'])\n",
    "y = current_df['upt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3309d5e6-5c80-4fb4-97a4-fb9baf5e251d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read optimal parameters\n",
    "file_path = os.path.join(current_directory, 'model_optimal_parameters.csv')\n",
    "optimal_parameters = pd.read_csv(file_path)\n",
    "\n",
    "# Subset the parameters only to the correct cluster\n",
    "optimal_row = optimal_parameters[(optimal_parameters['cluster'] == str(cluster_number - 1)) & (optimal_parameters['database'] == \"df\")].iloc[0]\n",
    "\n",
    "# Define all the parameters\n",
    "random_state_value = 42\n",
    "rf_n_estimators_value = int(optimal_row['rf_n_estimators'])\n",
    "rf_max_depth_value = optimal_row['rf_max_depth']\n",
    "rf_max_depth_value = None if rf_max_depth_value == 'None' else int(rf_max_depth_value)\n",
    "rf_min_samples_split_value = int(optimal_row['rf_min_samples_split'])\n",
    "rf_criterion_value = optimal_row['rf_criterion']\n",
    "rf_min_samples_leaf_value = int(optimal_row['rf_min_samples_leaf'])\n",
    "rf_max_features_value = None if pd.isna(optimal_row['rf_max_features']) else optimal_row['rf_max_features']\n",
    "svr_C_value = optimal_row['svr_C']\n",
    "svr_epsilon_value = optimal_row['svr_epsilon']\n",
    "gbr_n_estimators_value = int(optimal_row['gbr_n_estimators'])\n",
    "gbr_max_depth_value = optimal_row['gbr_max_depth']\n",
    "gbr_max_depth_value = None if gbr_max_depth_value == 'None' else int(gbr_max_depth_value)\n",
    "gbr_learning_rate_value = optimal_row['gbr_learning_rate']\n",
    "gbr_min_samples_split_value = int(optimal_row['gbr_min_samples_split'])\n",
    "gbr_min_samples_leaf_value = int(optimal_row['gbr_min_samples_leaf'])\n",
    "gbr_max_features_value = None if pd.isna(optimal_row['gbr_max_features']) else optimal_row['gbr_max_features']\n",
    "gbr_subsample_value = optimal_row['subsample']\n",
    "gbr_criterion_value = optimal_row['grb_criterion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70c2941e-b449-4b31-b3ef-e4b9adbb239f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models\n",
    "models = {\n",
    "    'rf': RandomForestRegressor(\n",
    "        n_estimators=rf_n_estimators_value,\n",
    "        n_jobs=-1,\n",
    "        max_depth=rf_max_depth_value,\n",
    "        min_samples_split=rf_min_samples_split_value,\n",
    "        random_state=random_state_value,\n",
    "        criterion=rf_criterion_value,\n",
    "        min_samples_leaf=rf_min_samples_leaf_value,\n",
    "        max_features=rf_max_features_value\n",
    "    ),\n",
    "    'svr': SVR(\n",
    "        kernel='linear',\n",
    "        C=svr_C_value,\n",
    "        epsilon=svr_epsilon_value\n",
    "    ),\n",
    "    'gbr': GradientBoostingRegressor(\n",
    "        n_estimators=gbr_n_estimators_value,\n",
    "        criterion=gbr_criterion_value,\n",
    "        learning_rate=gbr_learning_rate_value,\n",
    "        min_samples_split=gbr_min_samples_split_value,\n",
    "        max_depth=gbr_max_depth_value,\n",
    "        random_state=random_state_value,\n",
    "        min_samples_leaf=gbr_min_samples_leaf_value,\n",
    "        max_features=gbr_max_features_value,\n",
    "        subsample=gbr_subsample_value\n",
    "    )\n",
    "}\n",
    "\n",
    "# Train each model\n",
    "trained_models = {}\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X, y)\n",
    "    trained_models[model_name] = model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a53066b-4042-4dba-8095-5c02c15ca948",
   "metadata": {},
   "source": [
    "# Predict data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac416eb3-770d-4281-bd66-880e2c150623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize vectors to store predictions\n",
    "rf_predictions = []\n",
    "svr_predictions = []\n",
    "gbr_predictions = []\n",
    "\n",
    "# Predict data for each model and store predictions in vectors\n",
    "for model_name, model in trained_models.items():\n",
    "    # Make predictions\n",
    "    predictions = model.predict(x_prediction)\n",
    "    \n",
    "    # Store predictions in the corresponding vector\n",
    "    if model_name == 'rf':\n",
    "        rf_predictions = predictions\n",
    "    elif model_name == 'svr':\n",
    "        svr_predictions = predictions\n",
    "    elif model_name == 'gbr':\n",
    "        gbr_predictions = predictions\n",
    "\n",
    "# Add predictions to the DataFrame as new columns\n",
    "x_prediction['rf_prediction'] = rf_predictions\n",
    "x_prediction['svr_prediction'] = svr_predictions\n",
    "x_prediction['gbr_prediction'] = gbr_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f2bd8008-050d-45cd-8136-750f58e50c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally, save the DataFrame with predictions to a new CSV file\n",
    "output_file_path = os.path.join(current_directory, 'predictions_results.csv')\n",
    "x_prediction.to_csv(output_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc537eeb-7dfc-4237-9479-5c29a1d961eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "# Filter the feature importance DataFrame\n",
    "feature_importance_filtered = feature_importance[(feature_importance['df'] == 'df') & \n",
    "                                                 (feature_importance['run_type'] == 'optimal')]\n",
    "\n",
    "# Drop the 'df' and 'run_type' columns\n",
    "feature_importance_filtered = feature_importance_filtered.drop(columns=['df', 'run_type'])\n",
    "\n",
    "# Keep only the top 15 highest importance values per 'model' group\n",
    "top_features  = feature_importance_filtered.groupby(['model', 'cluster']).apply(lambda x: x.nlargest(10, 'importance')).reset_index(drop=True)\n",
    "\n",
    "# Classify the type of variable\n",
    "selected_features = ['OTP', 'fare', 'speed', 'voms', 'vrh','frequency_peak']\n",
    "top_features['Variables'] = np.where(top_features['feature'].isin(selected_features), 'Operational', 'Sociodemographic')\n",
    "\n",
    "top_features['model'] = top_features['model'].replace({'rf': 'Random Forest', 'gbr': 'Gradient Boosting'})\n",
    "\n",
    "top_features['importance'] = top_features['importance'].mask(top_features['importance'] < 0.001, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32348f2-8485-4731-9468-336664bb0a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "# Round up importance to the closest 0.2\n",
    "max_importance = np.ceil(top_features['importance'].max() * 10) / 10\n",
    "top_features['importance_cat'] = np.ceil(top_features['importance'] * 5) / 5\n",
    "\n",
    "# Define the colors for the custom colormap\n",
    "colors = sns.color_palette(\"viridis\", n_colors=9).as_hex()\n",
    "\n",
    "# Create a dictionary mapping importance to color\n",
    "color_map = {imp: color for imp, color in zip(np.arange(0, max_importance + 0.1, 0.1), colors)}\n",
    "\n",
    "# Create a custom colormap with discrete colors\n",
    "cmap = mcolors.ListedColormap([color_map[imp] for imp in np.arange(0, max_importance + 0.1, 0.1)])\n",
    "\n",
    "# Define a function to plot heatmap\n",
    "def plot_heatmap(data, **kwargs):\n",
    "    data = data.pivot(index='feature', columns='cluster', values='importance_cat')\n",
    "    ax = sns.heatmap(data, cmap=cmap, linewidths=1, linecolor='black', cbar=False, **kwargs)\n",
    "    return ax\n",
    "\n",
    "# Create FacetGrid with adjusted height and aspect ratio\n",
    "g = sns.FacetGrid(top_features, col='model', row='Variables', height=8, aspect=0.5, \n",
    "                   row_order=['Operational', 'Sociodemographic'], \n",
    "                   gridspec_kws={'height_ratios': [6, 25], 'hspace': 0.05},  # Specify height ratios for rows\n",
    "                   sharey='row',\n",
    "                   margin_titles=True)  # Place titles at the top and left\n",
    "\n",
    "# Add the heatmap\n",
    "g.map_dataframe(plot_heatmap)\n",
    "g.set_axis_labels(\"Clusters\", \"Variables\")\n",
    "\n",
    "# Add color bar and adjust layout\n",
    "cbar_ax = g.fig.add_axes([0.95, 0.25, 0.03, 0.5])  # Add a colorbar axis on the right side of the grid\n",
    "bounds = np.arange(0, max_importance + 0.1, 0.1)\n",
    "norm = mcolors.BoundaryNorm(bounds, cmap.N)\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "sm.set_array([])\n",
    "g.fig.colorbar(sm, ticks=bounds, cax=cbar_ax, orientation='vertical')  # Set orientation to vertical\n",
    "\n",
    "# Adjust the title and layout\n",
    "plt.show()\n",
    "plt.savefig(\"feature_importance.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d59bd5-020c-46f2-8321-f490093466ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_features['feature'].unique().tolist()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
