{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61f87706",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b337f230",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import skfuzzy as fuzz\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import jaccard_score, silhouette_score, davies_bouldin_score, calinski_harabasz_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.spatial.distance import jaccard\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage, fcluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19cc1f98",
   "metadata": {},
   "source": [
    "# Reading database "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93890429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get current working directory\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "# Name original database\n",
    "file_path = os.path.join(current_directory, 'training_dataset.csv')\n",
    "\n",
    "# Read training database\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a498048",
   "metadata": {},
   "source": [
    "# Defining cluster variables and scaling dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0c9301",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['spacing', 'interconnectivity', 'design', 'directness', 'service_area']].values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbca208a",
   "metadata": {},
   "source": [
    "# Finding optimum parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1035a33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define the range for c and m\n",
    "m_values = np.arange(1.3, 2.6, 0.1)\n",
    "c_values = range(2, 11)\n",
    "results = []\n",
    "\n",
    "\n",
    "# Evaluate FCM with varying c and m\n",
    "for m in m_values:\n",
    "    for c in c_values:\n",
    "        fcm = FCM(n_clusters=c, m=m, random_state=42)\n",
    "        fcm.fit(X_scaled)\n",
    "        labels = fcm.u.argmax(axis=1)\n",
    "        \n",
    "        # Calculate evaluation metrics\n",
    "        silhouette = silhouette_score(X_scaled, labels)\n",
    "        db_index = davies_bouldin_score(X_scaled, labels)\n",
    "        \n",
    "        # Store results\n",
    "        results.append({\n",
    "            'c': c,\n",
    "            'm': m,\n",
    "            'Silhouette Score': silhouette,\n",
    "            'Davies-Bouldin Index': db_index,\n",
    "        })\n",
    "\n",
    "# Convert results to a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Optionally, save the results to a CSV file\n",
    "results_df.to_csv('clustering_performance_measurementsf4.csv', index=False)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2117b890",
   "metadata": {},
   "source": [
    "# Clustering and deriving performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada2ddc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters chosen based on your analysis\n",
    "\n",
    "n_clusters = 5  # Replace with your chosen number of clusters\n",
    "m = 1.3  # Replace with your chosen fuzziness parameter\n",
    "\n",
    "\n",
    "\n",
    "def kmeans_plusplus_initializer(X, n_clusters):\n",
    "    n_samples, n_features = X.shape\n",
    "    centroids = np.zeros((n_clusters, n_features))\n",
    "    # Randomly choose the first centroid from the data points\n",
    "    initial_centroid_index = np.random.randint(n_samples)\n",
    "    centroids[0] = X[initial_centroid_index]\n",
    "\n",
    "    # Compute distances from the first centroid chosen to all the other data points\n",
    "    distances = np.linalg.norm(X - centroids[0], axis=1)\n",
    "    \n",
    "    for i in range(1, n_clusters):\n",
    "        # Choose next centroid with probability proportional to the square of the distance\n",
    "        probabilities = distances**2\n",
    "        probabilities /= probabilities.sum()\n",
    "        centroid_index = np.random.choice(n_samples, p=probabilities)\n",
    "        centroids[i] = X[centroid_index]\n",
    "\n",
    "        # Update distances after adding the new centroid\n",
    "        new_distances = np.linalg.norm(X - centroids[i], axis=1)\n",
    "        distances = np.minimum(distances, new_distances)\n",
    "    \n",
    "    return centroids\n",
    "\n",
    "# Initialize centroids using k-means++\n",
    "initial_centroids = kmeans_plusplus_initializer(X_scaled, n_clusters)\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "# Configure FCM with the initialized centroids\n",
    "fcm = FCM(n_clusters=n_clusters, m=m)\n",
    "fcm.fit(X_scaled)\n",
    "\n",
    "# Get the resulting labels and centers\n",
    "labels = fcm.u.argmax(axis=1)\n",
    "centers = fcm.centers\n",
    "\n",
    "# Evaluation metrics\n",
    "silhouette = silhouette_score(X_scaled, labels)\n",
    "db_index = davies_bouldin_score(X_scaled, labels)\n",
    "calinski_harabasz = calinski_harabasz_score(X_scaled, labels)\n",
    "\n",
    "# Calculate Average Shortest Euclidean Distance between centers\n",
    "distances = np.linalg.norm(centers[:, np.newaxis] - centers, axis=2)\n",
    "np.fill_diagonal(distances, np.inf)\n",
    "avg_shortest_distance = np.min(distances)\n",
    "\n",
    "# Stability using Adjusted Rand Index\n",
    "# Note: Ensure you have a previous run or a baseline to compare with, or simulate another run here\n",
    "previous_labels = np.copy(labels)  # Simulating previous run for example purposes\n",
    "fcm.fit(X_scaled)  # Another run (simulating for stability check)\n",
    "new_labels = fcm.u.argmax(axis=1)\n",
    "stability_ari = adjusted_rand_score(previous_labels, new_labels)\n",
    "\n",
    "# Output the results\n",
    "print(\"Evaluation Metrics:\")\n",
    "print(f\"Silhouette Score: {silhouette}\")\n",
    "print(f\"Davies-Bouldin Score: {db_index}\")\n",
    "print(f\"Calinski-Harabasz Score: {calinski_harabasz}\")\n",
    "print(f\"Average Shortest Euclidean Distance: {avg_shortest_distance}\")\n",
    "print(f\"Stability ARI: {stability_ari}\")\n",
    "print(\"Cluster Centers:\\n\", centers)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58cc1483",
   "metadata": {},
   "source": [
    "# Adding cluster variable to dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e646fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['Cluster'] = fcm.u.argmax(axis=1)\n",
    "\n",
    "# Calculate summary statistics for each cluster\n",
    "cluster_summary = df.groupby('Cluster').agg({\n",
    "    'spacing': ['mean', 'std', 'min', 'max'],\n",
    "    'interconnectivity': ['mean', 'std', 'min', 'max'],\n",
    "    'design': ['mean', 'std', 'min', 'max'],\n",
    "    'directness': ['mean', 'std', 'min', 'max'],\n",
    "    'service_area': ['mean', 'std', 'min', 'max'],\n",
    "    'Cluster': 'count'\n",
    "})\n",
    "\n",
    "# Rename the 'count' column for clarity\n",
    "cluster_summary = cluster_summary.rename(columns={'count': 'Number of Units'})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
